{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid2Op integration with existing frameworks\n",
    "\n",
    "Try me out interactively with: [![Binder](./img/badge_logo.svg)](https://mybinder.org/v2/gh/Grid2Op/grid2op/master)\n",
    "\n",
    "\n",
    "**objectives** This notebooks briefly explains how to use grid2op with commonly used RL frameworks. It also explains the main methods / class of the `grid2op.gym_compat` module that ease grid2op integration with these frameworks.\n",
    "\n",
    "<font color='red'> This explains the ideas and shows a \"self contained\" somewhat minimal example of use of some RL frameworks with grid2op. For a more complete, easier, more concise, etc. integration, please use the \"l2rpn_baselines\" package. </font> \n",
    "\n",
    "\n",
    "The structure is always very similar:\n",
    "1. Create a grid2op environment\n",
    "2. Convert it to a gym environment\n",
    "3. (optional) Customize the action space and observation space\n",
    "4. Use the framework to train an agent\n",
    "5. Embed the trained agent into a grid2op Agent to take valid grid2op actions.\n",
    "\n",
    "In this notebook, we will demonstrate its usage with 3 different framework. The code provided here are given as examples and we do not assume anything on their performance or fitness of use. More detailed example will be provided in the l2rpn-baselines repository in due time (work in progress at the time of writing this notebook). The 3 framework we will demonstrate an example of are:\n",
    "\n",
    "- ray (rllib): see [ray on github](https://github.com/ray-project/ray) or [rllib on github](https://github.com/ray-project/ray/blob/master/doc/source/rllib.rst)\n",
    "- stable-baselines3: see [stable-baselines3 on github](https://github.com/DLR-RM/stable-baselines3)\n",
    "- tf_agents: see [tf_agents on github](https://github.com/tensorflow/agents)\n",
    "\n",
    "Other RL frameworks are not cover here. If you already use them, let us know !\n",
    "- https://github.com/PaddlePaddle/PARL/blob/develop/README.md (used by the winner teams of Neurips competitions !) Work in progress.\n",
    "- https://github.com/deepmind/acme\n",
    "\n",
    "Note also that there is still the possibility to use past codes in the l2rpn-baselines repository: https://github.com/grid2op/l2rpn-baselines . This repository contains code snippets that can be reuse to make really nice agents on the l2rpn competitions. You can try it out :-) \n",
    "\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" width=\"200\">\n",
    "Execute the cell below by removing the `#` characters if you use google colab !\n",
    "\n",
    "Cell will look like:\n",
    "```python\n",
    "import sys\n",
    "!$sys.executable install grid2op[optional]  # for use with google colab (grid2Op is not installed by default)\n",
    "!$sys.executable install tensorflow pytorch stable-baselines3 'ray[rllib]' tf_agents\n",
    "```\n",
    "\n",
    "It might take a while\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !$sys.executable -m pip install grid2op[optional]  # for use with google colab (grid2Op is not installed by default)\n",
    "# !$sys.executable -m pip install stable-baselines3 'ray[rllib]' tf_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because this notebook is part of some tests, we train the agent for only a small number of steps\n",
    "nb_step_train = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organisation of this notebook\n",
    "\n",
    "For the organisation of this notebook we decided to first detail features closer to grid2op to go later on \"higher level\" feature that are closer to \"standard\" gym representation (eg `Box` and `Discrete` space).\n",
    "\n",
    "Note the closer you are to grid2op the more grid2op feature you can use. For example, in gym environment, it is not possible to use the \"simulate\" function (remember, this function allow to use a simulator that has a behaviour close to the one of the environment) at all. Also, grid2op observation and action comes with a lot of different feature (capacity to add them, to retrieve the graph of the grid etc.) which is not possible to use directly in gym.\n",
    "\n",
    "That being said, this notebook is organized as follow:\n",
    "\n",
    "- [Convert it to a gym environment](#Convert-it-to-a-gym-environment): basic use of the `gym_compat` grid2op module allowing to convert a grid2op environment to a gym environment.\n",
    "- [Action space](#Action-space): basic usage of the action space, by removing redundant feature (`gym_env.observation_space.ignore_attr`) or transforming feature from a continuous space to a discrete space (`ContinuousToDiscreteConverter`)\n",
    "- [Observation space](#Observation-space): basic usage of the observation space, by removing redunddant features (`keep_only_attr`) or to scale the data on between a certain range (`ScalerAttrConverter`)\n",
    "- [Making the grid2op agent](#Making-the-grid2op-agent) explains how to make a grid2op agent once trained. Note that a more \"agent focused\" view is provided in the notebook [04_TrainingAnAgent](04_TrainingAnAgent.ipynb) !\n",
    "\n",
    "To dive deeper and with proper \"hands on\", you can refer to one of the following notebooks that uses real RL frameworks:\n",
    "\n",
    "1) RLLIB: see notebook [11_ray_integration](./11_ray_integration.ipynb) for more information about RLLIB\n",
    "2) Stable baselines: see notebook [11_ray_integration](./11_stable_baselines3_integration.ipynb) for more information about stables-baselines3\n",
    "3) tf agents: coming soon\n",
    "4) acme: coming soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Recommended initial steps\n",
    "\n",
    "\n",
    "### Split the environment into training, validation and test\n",
    "\n",
    "As in other machine learning tasks, we highly recommend, before even trying to train an agent, to split the \"chronics\" (ie the episode data) into 3 datasets:\n",
    "- \"train\" use to train the agent\n",
    "- \"val\" use to validate the hyper parameters\n",
    "- \"test\" at which you would look only once to report the agent performance in a scientific paper (for example)\n",
    "\n",
    "Grid2op lets you do that with relative ease:\n",
    "\n",
    "```python\n",
    "import grid2op\n",
    "env_name = \"l2rpn_case14_sandbox\"  # or any other...\n",
    "env = grid2op.make(env_name)\n",
    "\n",
    "# extract 1% of the \"chronics\" to be used in the validation environment. The other 99% will\n",
    "# be used for test\n",
    "nm_env_train, nm_env_val, nm_env_test = env.train_val_split_random(pct_val=1., pct_test=1.)\n",
    "\n",
    "# and now you can use the training set only to train your agent:\n",
    "print(f\"The name of the training environment is \\\\\"{nm_env_train}\\\\\"\")\n",
    "print(f\"The name of the validation environment is \\\\\"{nm_env_val}\\\\\"\")\n",
    "print(f\"The name of the test environment is \\\\\"{nm_env_test}\\\\\"\")\n",
    "```\n",
    "\n",
    "And now, you can use the training environment to train your agent:\n",
    "\n",
    "```python\n",
    "import grid2op\n",
    "env_name = \"l2rpn_case14_sandbox\"\n",
    "env = grid2op.make(env_name+\"train\")\n",
    "```\n",
    "\n",
    "Be carefull, on windows you might run into issues. Don't hesitate to have a look at the documentation of this funciton if this the case (see https://grid2op.readthedocs.io/en/latest/environment.html#grid2op.Environment.Environment.train_val_split and https://grid2op.readthedocs.io/en/latest/environment.html#grid2op.Environment.Environment.train_val_split_random)\n",
    "\n",
    "More information are provided here: https://grid2op.readthedocs.io/en/latest/environment.html#splitting-into-raining-validation-test-scenarios\n",
    "\n",
    "### Use the `experimental_read_from_local_dir` flag\n",
    "\n",
    "This flag allows python to better \"understands\" the classes in grid2op and avoid lots of issue with pickle / multi processing etc.\n",
    "\n",
    "The complete documentation is available here https://grid2op.readthedocs.io/en/latest/environment.html#grid2op.Environment.BaseEnv.generate_classes\n",
    "\n",
    "Basically, once, and only once, outside of this process, you can call:\n",
    "\n",
    "```python\n",
    "import grid2op\n",
    "env_name = \"l2rpn_case14_sandbox\"  # or any other name\n",
    "\n",
    "env = grid2op.make(env_name, ...)  # again: redo this step each time you customize \"...\"\n",
    "# for example if you change the `action_class` or the `backend` etc.\n",
    "\n",
    "env.generate_classes()\n",
    "```\n",
    "\n",
    "Then, each time you want to reload the same environment, you can do:\n",
    "\n",
    "```python\n",
    "import grid2op\n",
    "env_name = SAME NAME AS ABOVE\n",
    "env = grid2op.make(env_name,\n",
    "                   experimental_read_from_local_dir=True,\n",
    "                   ..., # SAME ENV CUSTOMIZATION AS ABOVE\n",
    "                  )\n",
    "```\n",
    "\n",
    "This is known to solve bug related to multi processing, but also to reduce the amount of RAM taken (in some cases) as well as creation time (in some cases)\n",
    "\n",
    "### Other steps\n",
    "\n",
    "The grid2op documentation is full of details to \"optimize\" the number of steps you can do per seconds. This number can rise from a few dozen per seconds to around a thousands per seconds with proper care.\n",
    "\n",
    "We strongly encouraged you to leverage all the possibilities which includes (but are not limited to):\n",
    "- using \"lightsim2grid\" as a backend for a 10-15x speed up in the \"env.step(...)\" function\n",
    "- using \"MultifolderWithCache\" or \"env.chronics_handler.set_chunk(...)\" for faster \"env.reset(...)\" see https://grid2op.readthedocs.io/en/latest/environment.html#optimize-the-data-pipeline\n",
    "\n",
    "\n",
    "### Create a grid2op environment\n",
    "\n",
    "This is a rather standard step, with lots of inspiration drawn from openAI gym framework, and there is absolutely no specificity here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\grid2op\\Backend\\pandaPowerBackend.py:36: UserWarning: Numba cannot be loaded. You will gain possibly massive speed if installing it by \n",
      "\tc:\\Users\\admin\\Grid2Op\\venv_g2op\\Scripts\\python.exe -m pip install numba\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\grid2op\\MakeEnv\\Make.py:454: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    }
   ],
   "source": [
    "import grid2op\n",
    "try:\n",
    "    from lightsim2grid import LightSimBackend\n",
    "    bk_cls = LightSimBackend\n",
    "except ImportError as exc:\n",
    "    print(f\"Error: {exc} when importing faster LightSimBackend\")\n",
    "    from grid2op.Backend import PandaPowerBackend\n",
    "    bk_cls = PandaPowerBackend\n",
    "    \n",
    "env_name = \"l2rpn_case14_sandbox\"\n",
    "env_glop = grid2op.make(env_name, test=True, backend=bk_cls())\n",
    "# NOTE: do not set the flag \"test=True\" for a real usage !\n",
    "# NOTE: use grid2op.make(env_name+\"_train\", test=True) for a real usage (see paragraph above !)\n",
    "\n",
    "# This flag is here for testing purpose !!!\n",
    "obs_glop = env_glop.reset()\n",
    "# obs_glop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<grid2op.Space.GridObjects.ActionSpace_l2rpn_case14_sandbox at 0x1332bbcfa00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_glop.action_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ActionSpace_l2rpn_case14_sandbox' object has no attribute 'spaces'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43menv_glop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspaces\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ActionSpace_l2rpn_case14_sandbox' object has no attribute 'spaces'"
     ]
    }
   ],
   "source": [
    "env_glop.action_space.spaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert it to a gym environment\n",
    "\n",
    "To that end, we recommend using the \"gym_compat\" module. More information is given in the [official grid2op documentation](https://grid2op.readthedocs.io/en/latest/gym.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"env_gym\" is a gym environment: True\n"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "from grid2op.gym_compat import GymEnv\n",
    "env_gym_init = GymEnv(env_glop)\n",
    "env_gym = GymEnv(env_glop)\n",
    "print(f\"The \\\"env_gym\\\" is a gym environment: {isinstance(env_gym, gymnasium.Env)}\")\n",
    "obs_gym, info = env_gym.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<grid2op.Space.GridObjects.ObservationSpace_l2rpn_case14_sandbox at 0x1332bbcfee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_glop.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize the action space and observation space\n",
    "\n",
    "This step is optional, but highly recommended.\n",
    "\n",
    "By default, grid2op actions and observations are huge. Even for this very simplistic example, you have really important sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(env_gym.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shunt_bus': Box(-2147483648, 2147483647, (1,), int32),\n",
       " '_shunt_p': Box(-inf, inf, (1,), float32),\n",
       " '_shunt_q': Box(-inf, inf, (1,), float32),\n",
       " '_shunt_v': Box(-inf, inf, (1,), float32),\n",
       " 'a_ex': Box(0.0, inf, (20,), float32),\n",
       " 'a_or': Box(0.0, inf, (20,), float32),\n",
       " 'actual_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32),\n",
       " 'attention_budget': Box(0.0, inf, (1,), float32),\n",
       " 'current_step': Box(-2147483648, 2147483647, (1,), int32),\n",
       " 'curtailment': Box(0.0, 1.0, (6,), float32),\n",
       " 'curtailment_limit': Box(0.0, 1.0, (6,), float32),\n",
       " 'curtailment_limit_effective': Box(0.0, 1.0, (6,), float32),\n",
       " 'day': Discrete(32),\n",
       " 'day_of_week': Discrete(8),\n",
       " 'delta_time': Box(0.0, inf, (1,), float32),\n",
       " 'duration_next_maintenance': Box(-1, 2147483647, (20,), int32),\n",
       " 'gen_margin_down': Box(0.0, [ 5. 10.  0.  0.  0. 15.], (6,), float32),\n",
       " 'gen_margin_up': Box(0.0, [ 5. 10.  0.  0.  0. 15.], (6,), float32),\n",
       " 'gen_p': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32),\n",
       " 'gen_p_before_curtail': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32),\n",
       " 'gen_q': Box(-inf, inf, (6,), float32),\n",
       " 'gen_theta': Box(-180.0, 180.0, (6,), float32),\n",
       " 'gen_v': Box(0.0, inf, (6,), float32),\n",
       " 'hour_of_day': Discrete(24),\n",
       " 'is_alarm_illegal': Discrete(2),\n",
       " 'line_status': MultiBinary(20),\n",
       " 'load_p': Box(-inf, inf, (11,), float32),\n",
       " 'load_q': Box(-inf, inf, (11,), float32),\n",
       " 'load_theta': Box(-180.0, 180.0, (11,), float32),\n",
       " 'load_v': Box(0.0, inf, (11,), float32),\n",
       " 'max_step': Box(-2147483648, 2147483647, (1,), int32),\n",
       " 'minute_of_hour': Discrete(60),\n",
       " 'month': Discrete(13),\n",
       " 'p_ex': Box(-inf, inf, (20,), float32),\n",
       " 'p_or': Box(-inf, inf, (20,), float32),\n",
       " 'q_ex': Box(-inf, inf, (20,), float32),\n",
       " 'q_or': Box(-inf, inf, (20,), float32),\n",
       " 'rho': Box(0.0, inf, (20,), float32),\n",
       " 'target_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32),\n",
       " 'thermal_limit': Box(0.0, inf, (20,), float32),\n",
       " 'theta_ex': Box(-180.0, 180.0, (20,), float32),\n",
       " 'theta_or': Box(-180.0, 180.0, (20,), float32),\n",
       " 'time_before_cooldown_line': Box(0, 10, (20,), int32),\n",
       " 'time_before_cooldown_sub': Box(0, 0, (14,), int32),\n",
       " 'time_next_maintenance': Box(-1, 2147483647, (20,), int32),\n",
       " 'time_since_last_alarm': Box(-1, 2147483647, (1,), int32),\n",
       " 'timestep_overflow': Box(-2147483648, 2147483647, (20,), int32),\n",
       " 'topo_vect': Box(-1, 2, (57,), int32),\n",
       " 'v_ex': Box(0.0, inf, (20,), float32),\n",
       " 'v_or': Box(0.0, inf, (20,), float32),\n",
       " 'was_alarm_used_after_game_over': Discrete(2),\n",
       " 'year': Discrete(2100)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_gym.observation_space.spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the action space is : 166\n",
      "The size of the observation space is : 536\n"
     ]
    }
   ],
   "source": [
    "dim_act_space = np.sum([np.sum(env_gym.action_space[el].shape) for el in env_gym.action_space.spaces])\n",
    "print(f\"The size of the action space is : \"\n",
    "      f\"{dim_act_space}\")\n",
    "dim_obs_space = np.sum([np.sum(env_gym.observation_space[el].shape).astype(int) \n",
    "                        for el in env_gym.observation_space.spaces])\n",
    "print(f\"The size of the observation space is : \"\n",
    "      f\"{dim_obs_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action space\n",
    "This is partly due because in grid2op, you can represent the same concept (*eg* reconnect a powerline) in different manners (in this case: either you \"toggle a switch\" - if the said powerline was connected, it will disconnect it, otherwise it will reconnect it- or you can say \"i want this line connected whatever its original state\"). This behaviour is detailed in the [official grid2op documentation](https://grid2op.readthedocs.io/en/latest/action.html#usage-examples).\n",
    "\n",
    "To (in general) reduce the action space by a factor of 2, you can represent these actions only using the change method (for example). You can do that with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new size of the action space is : 89\n"
     ]
    }
   ],
   "source": [
    "# example: ignore the \"set_status\" and \"set_bus\" type of actions, that are covered by the \"change_status\" and\n",
    "# \"change_bus\"\n",
    "#print(env_gym.action_space)\n",
    "#print()\n",
    "env_gym.action_space = env_gym.action_space.ignore_attr(\"set_bus\").ignore_attr(\"set_line_status\")\n",
    "#print(env_gym.action_space)\n",
    "#print()\n",
    "new_dim_act_space = np.sum([np.sum(env_gym.action_space[el].shape) for el in env_gym.action_space.spaces])\n",
    "print(f\"The new size of the action space is : {new_dim_act_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid2op environments allow for both continuous and discrete action. For the sake of the example, let's \"convert\" the continuous actions in discrete ones (this is done with \"binning\" the values as explained in more details [in the documentation](https://grid2op.readthedocs.io/en/latest/gym.html#grid2op.gym_compat.ContinuousToDiscreteConverter) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'change_bus': array([0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8),\n",
       " 'change_line_status': array([1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0],\n",
       "       dtype=int8),\n",
       " 'curtail': array([-1.        , -1.        ,  0.6041282 ,  0.27099356,  0.8444675 ,\n",
       "        -1.        ], dtype=float32),\n",
       " 'redispatch': array([  4.241563,   2.210168,   0.      ,   0.      ,   0.      ,\n",
       "        -14.398382], dtype=float32),\n",
       " 'set_bus': array([ 2,  2, -1,  0,  0, -1,  1,  0,  1, -1, -1,  0,  1, -1,  2,  2,  0,\n",
       "         0,  1,  0,  0,  0,  2, -1,  0, -1,  2,  0,  2, -1,  1,  2,  2, -1,\n",
       "        -1,  2,  1,  1, -1,  2, -1,  0, -1,  0,  1, -1,  0,  0,  0,  0,  0,\n",
       "         2,  1,  1,  0,  0, -1]),\n",
       " 'set_line_status': array([-1, -1, -1,  0, -1,  0, -1,  0,  1,  1, -1,  0, -1,  0,  0,  0,  0,\n",
       "        -1,  1,  0])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = env_gym.action_space.sample()\n",
    "aa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: convert the continuous action type \"redispatch\" to a discrete action type\n",
    "from grid2op.gym_compat import ContinuousToDiscreteConverter\n",
    "env_gym.action_space = env_gym.action_space.reencode_space(\"redispatch\",\n",
    "                                                           ContinuousToDiscreteConverter(nb_bins=11)\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('change_bus': MultiBinary(57), 'change_line_status': MultiBinary(20), 'curtail': Box([-1. -1.  0.  0.  0. -1.], [-1. -1.  1.  1.  1. -1.], (6,), float32), 'redispatch': MultiDiscrete([11 11  1  1  1 11]), 'set_bus': Box(-1, 2, (57,), int32), 'set_line_status': Box(-1, 1, (20,), int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now our action space looks like:\n",
    "env_gym.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'change_bus': MultiBinary(57),\n",
       " 'change_line_status': MultiBinary(20),\n",
       " 'curtail': Box([-1. -1.  0.  0.  0. -1.], [-1. -1.  1.  1.  1. -1.], (6,), float32),\n",
       " 'redispatch': MultiDiscrete([11 11  1  1  1 11]),\n",
       " 'set_bus': Box(-1, 2, (57,), int32),\n",
       " 'set_line_status': Box(-1, 1, (20,), int32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_gym.action_space.spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\grid2op\\MakeEnv\\Make.py:454: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redispatch structure in gym action: [2 3 0 0 0 0]\n",
      "\n",
      "Action with index 2 (midpoint values):\n",
      "This action will:\n",
      "\t - NOT change anything to the injections\n",
      "\t - Modify the generators with redispatching in the following way:\n",
      "\t \t - Redispatch \"gen_1_0\" of -1.67 MW\n",
      "\t \t - Redispatch \"gen_2_1\" of -3.33 MW\n",
      "\t \t - Redispatch \"gen_0_5\" of -5.00 MW\n",
      "\t - NOT modify any storage capacity\n",
      "\t - Perform the following curtailment:\n",
      "\t \t - Limit unit \"gen_5_2\" to 77.3% of its Pmax (setpoint: 0.773)\n",
      "\t \t - Limit unit \"gen_5_3\" to 44.2% of its Pmax (setpoint: 0.442)\n",
      "\t \t - Limit unit \"gen_7_4\" to 86.3% of its Pmax (setpoint: 0.863)\n",
      "\t - NOT force any line status\n",
      "\t - Switch status of 11 powerlines ([ 0  1  4  6 10 11 13 14 16 17 18])\n",
      "\t - Change the bus of the following element(s):\n",
      "\t \t - Switch bus of line (origin) id 2 [on substation 1]\n",
      "\t \t - Switch bus of line (origin) id 5 [on substation 2]\n",
      "\t \t - Switch bus of load id 1 [on substation 2]\n",
      "\t \t - Switch bus of line (extremity) id 3 [on substation 3]\n",
      "\t \t - Switch bus of line (extremity) id 5 [on substation 3]\n",
      "\t \t - Switch bus of line (origin) id 15 [on substation 3]\n",
      "\t \t - Switch bus of line (origin) id 16 [on substation 3]\n",
      "\t \t - Switch bus of line (extremity) id 4 [on substation 4]\n",
      "\t \t - Switch bus of line (extremity) id 6 [on substation 4]\n",
      "\t \t - Switch bus of line (origin) id 17 [on substation 4]\n",
      "\t \t - Switch bus of load id 3 [on substation 4]\n",
      "\t \t - Switch bus of line (origin) id 9 [on substation 5]\n",
      "\t \t - Switch bus of line (extremity) id 17 [on substation 5]\n",
      "\t \t - Switch bus of generator id 3 [on substation 5]\n",
      "\t \t - Switch bus of load id 4 [on substation 5]\n",
      "\t \t - Switch bus of line (extremity) id 18 [on substation 7]\n",
      "\t \t - Switch bus of generator id 4 [on substation 7]\n",
      "\t \t - Switch bus of line (origin) id 10 [on substation 8]\n",
      "\t \t - Switch bus of line (extremity) id 16 [on substation 8]\n",
      "\t \t - Switch bus of load id 6 [on substation 9]\n",
      "\t \t - Switch bus of line (extremity) id 7 [on substation 10]\n",
      "\t \t - Switch bus of line (extremity) id 12 [on substation 10]\n",
      "\t \t - Switch bus of load id 7 [on substation 10]\n",
      "\t \t - Switch bus of line (extremity) id 8 [on substation 11]\n",
      "\t \t - Switch bus of line (origin) id 13 [on substation 11]\n",
      "\t \t - Switch bus of line (extremity) id 13 [on substation 12]\n",
      "\t \t - Switch bus of load id 9 [on substation 12]\n",
      "\t \t - Switch bus of line (extremity) id 11 [on substation 13]\n",
      "\t \t - Switch bus of load id 10 [on substation 13]\n",
      "\t - NOT force any particular bus configuration\n",
      "\n",
      "Redispatch amounts:\n",
      "Generator 0: -1.666700005531311 MW\n",
      "Generator 1: -3.3333001136779785 MW\n",
      "Generator 2: 0.0 MW\n",
      "Generator 3: 0.0 MW\n",
      "Generator 4: 0.0 MW\n",
      "Generator 5: -5.0 MW\n"
     ]
    }
   ],
   "source": [
    "import grid2op\n",
    "from grid2op.gym_compat import GymEnv, ContinuousToDiscreteConverter\n",
    "\n",
    "# 1. Create Grid2Op environment\n",
    "env = grid2op.make(\"l2rpn_case14_sandbox\", test=True)\n",
    "obs = env.reset()\n",
    "\n",
    "# 2. Create Gym environment\n",
    "gym_env = GymEnv(env)\n",
    "\n",
    "gym_env.action_space = gym_env.action_space.ignore_attr(\n",
    "                                            \"set_bus\").ignore_attr(\n",
    "                                            \"set_line_status\")\n",
    "\n",
    "# 3. Reencode the \"redispatch\" action space to use discrete bins\n",
    "gym_env.action_space = gym_env.action_space.reencode_space(\n",
    "    \"redispatch\", ContinuousToDiscreteConverter(nb_bins=5)\n",
    ")\n",
    "act_space = gym_env.action_space\n",
    "\n",
    "# 4. Create a default Gym action\n",
    "gym_action = gym_env.action_space.sample()\n",
    "gym_action\n",
    "\n",
    "\n",
    "# 5. Modify the gym_action correctly\n",
    "# First, check the structure of the redispatch part of the action space\n",
    "print(\"Redispatch structure in gym action:\", gym_action[\"redispatch\"])\n",
    "\n",
    "# The correct way to set redispatch values depends on the actual structure\n",
    "# Assuming it's an array where we need to set all values to 2:\n",
    "gym_action[\"redispatch\"][:] = 1\n",
    "\n",
    "# 6. Convert back to Grid2Op action and print\n",
    "grid2op_action = gym_env.action_space.from_gym(gym_action)\n",
    "\n",
    "print(\"\\nAction with index 2 (midpoint values):\")\n",
    "print(grid2op_action)\n",
    "\n",
    "# 7. Show actual redispatch values\n",
    "print(\"\\nRedispatch amounts:\")\n",
    "for gen_id, val in enumerate(grid2op_action.redispatch):\n",
    "    print(f\"Generator {gen_id}: {round(val, 4)} MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6666665, -3.333333 ,  0.       ,  0.       ,  0.       ,\n",
       "       -5.       ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2op_action.redispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.n_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also have the possibility to use other types of more common action space.\n",
    "\n",
    "#### More customization for the action space\n",
    "\n",
    "For example, just like in most Atari Games, you can encode each unary action by an integer (for example \"0\" might be \"turn left\", \"1\" \"turn right\" etc.) and have your argent predict the ID of the action instead of its complex form.\n",
    "\n",
    "This action space will \"automatically\" transform continuous actions into discrete by \"binning\" (more information on the official documentation for example here )\n",
    "\n",
    "This can be achieved with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 544 independant actions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\grid2op\\gym_compat\\discrete_gym_actspace.py:260: UserWarning: The class \"DiscreteActSpace\" should mainly be used to consider only discrete actions (eg. set_line_status, set_bus or change_bus). Though it is possible to use \"curtail\" when building it, be aware that this continuous action will be treated as discrete by splitting it into bins. Consider using the \"BoxGymActSpace\" for these attributes.\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\grid2op\\gym_compat\\discrete_gym_actspace.py:260: UserWarning: The class \"DiscreteActSpace\" should mainly be used to consider only discrete actions (eg. set_line_status, set_bus or change_bus). Though it is possible to use \"redispatch\" when building it, be aware that this continuous action will be treated as discrete by splitting it into bins. Consider using the \"BoxGymActSpace\" for these attributes.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discrete(544)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from grid2op.gym_compat import DiscreteActSpace\n",
    "env_gym.action_space = DiscreteActSpace(env_gym.init_env.action_space)\n",
    "print(f\"There are {env_gym.action_space.n} independant actions\")\n",
    "env_gym.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can customize it even more, for example if you have at your disposal a list of grid2op actions you want to use (and not use the other one, this is explained in the documentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation space\n",
    "\n",
    "For the obsevation space, we will remove lots of useless attributes (remember, it is for the sake of the example here, and rescale some other so that they have numbers between rougly 0. and 1., which stabilizes the learning process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('_shunt_bus': Box(-2147483648, 2147483647, (1,), int32), '_shunt_p': Box(-inf, inf, (1,), float32), '_shunt_q': Box(-inf, inf, (1,), float32), '_shunt_v': Box(-inf, inf, (1,), float32), 'a_ex': Box(0.0, inf, (20,), float32), 'a_or': Box(0.0, inf, (20,), float32), 'actual_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32), 'attention_budget': Box(0.0, inf, (1,), float32), 'current_step': Box(-2147483648, 2147483647, (1,), int32), 'curtailment': Box(0.0, 1.0, (6,), float32), 'curtailment_limit': Box(0.0, 1.0, (6,), float32), 'curtailment_limit_effective': Box(0.0, 1.0, (6,), float32), 'day': Discrete(32), 'day_of_week': Discrete(8), 'delta_time': Box(0.0, inf, (1,), float32), 'duration_next_maintenance': Box(-1, 2147483647, (20,), int32), 'gen_margin_down': Box(0.0, [ 5. 10.  0.  0.  0. 15.], (6,), float32), 'gen_margin_up': Box(0.0, [ 5. 10.  0.  0.  0. 15.], (6,), float32), 'gen_p': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32), 'gen_p_before_curtail': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32), 'gen_q': Box(-inf, inf, (6,), float32), 'gen_theta': Box(-180.0, 180.0, (6,), float32), 'gen_v': Box(0.0, inf, (6,), float32), 'hour_of_day': Discrete(24), 'is_alarm_illegal': Discrete(2), 'line_status': MultiBinary(20), 'load_p': Box(-inf, inf, (11,), float32), 'load_q': Box(-inf, inf, (11,), float32), 'load_theta': Box(-180.0, 180.0, (11,), float32), 'load_v': Box(0.0, inf, (11,), float32), 'max_step': Box(-2147483648, 2147483647, (1,), int32), 'minute_of_hour': Discrete(60), 'month': Discrete(13), 'p_ex': Box(-inf, inf, (20,), float32), 'p_or': Box(-inf, inf, (20,), float32), 'q_ex': Box(-inf, inf, (20,), float32), 'q_or': Box(-inf, inf, (20,), float32), 'rho': Box(0.0, inf, (20,), float32), 'target_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32), 'thermal_limit': Box(0.0, inf, (20,), float32), 'theta_ex': Box(-180.0, 180.0, (20,), float32), 'theta_or': Box(-180.0, 180.0, (20,), float32), 'time_before_cooldown_line': Box(0, 10, (20,), int32), 'time_before_cooldown_sub': Box(0, 0, (14,), int32), 'time_next_maintenance': Box(-1, 2147483647, (20,), int32), 'time_since_last_alarm': Box(-1, 2147483647, (1,), int32), 'timestep_overflow': Box(-2147483648, 2147483647, (20,), int32), 'topo_vect': Box(-1, 2, (57,), int32), 'v_ex': Box(0.0, inf, (20,), float32), 'v_or': Box(0.0, inf, (20,), float32), 'was_alarm_used_after_game_over': Discrete(2), 'year': Discrete(2100))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first let's see which are the attributes in the observation space:\n",
    "# More information on\n",
    "# https://beta-grid2op.readthedocs.io/en/latest/observation.html#main-observation-attributes\n",
    "# and \n",
    "# https://grid2op.readthedocs.io/en/latest/gym.html#observation-space-and-action-space-customization\n",
    "env_gym.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shunt_bus': Box(-2147483648, 2147483647, (1,), int32),\n",
       " '_shunt_p': Box(-inf, inf, (1,), float32),\n",
       " '_shunt_q': Box(-inf, inf, (1,), float32),\n",
       " '_shunt_v': Box(-inf, inf, (1,), float32),\n",
       " 'a_ex': Box(0.0, inf, (20,), float32),\n",
       " 'a_or': Box(0.0, inf, (20,), float32),\n",
       " 'actual_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32),\n",
       " 'attention_budget': Box(0.0, inf, (1,), float32),\n",
       " 'current_step': Box(-2147483648, 2147483647, (1,), int32),\n",
       " 'curtailment': Box(0.0, 1.0, (6,), float32),\n",
       " 'curtailment_limit': Box(0.0, 1.0, (6,), float32),\n",
       " 'curtailment_limit_effective': Box(0.0, 1.0, (6,), float32),\n",
       " 'day': Discrete(32),\n",
       " 'day_of_week': Discrete(8),\n",
       " 'delta_time': Box(0.0, inf, (1,), float32),\n",
       " 'duration_next_maintenance': Box(-1, 2147483647, (20,), int32),\n",
       " 'gen_margin_down': Box(0.0, [ 5. 10.  0.  0.  0. 15.], (6,), float32),\n",
       " 'gen_margin_up': Box(0.0, [ 5. 10.  0.  0.  0. 15.], (6,), float32),\n",
       " 'gen_p': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32),\n",
       " 'gen_p_before_curtail': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32),\n",
       " 'gen_q': Box(-inf, inf, (6,), float32),\n",
       " 'gen_theta': Box(-180.0, 180.0, (6,), float32),\n",
       " 'gen_v': Box(0.0, inf, (6,), float32),\n",
       " 'hour_of_day': Discrete(24),\n",
       " 'is_alarm_illegal': Discrete(2),\n",
       " 'line_status': MultiBinary(20),\n",
       " 'load_p': Box(-inf, inf, (11,), float32),\n",
       " 'load_q': Box(-inf, inf, (11,), float32),\n",
       " 'load_theta': Box(-180.0, 180.0, (11,), float32),\n",
       " 'load_v': Box(0.0, inf, (11,), float32),\n",
       " 'max_step': Box(-2147483648, 2147483647, (1,), int32),\n",
       " 'minute_of_hour': Discrete(60),\n",
       " 'month': Discrete(13),\n",
       " 'p_ex': Box(-inf, inf, (20,), float32),\n",
       " 'p_or': Box(-inf, inf, (20,), float32),\n",
       " 'q_ex': Box(-inf, inf, (20,), float32),\n",
       " 'q_or': Box(-inf, inf, (20,), float32),\n",
       " 'rho': Box(0.0, inf, (20,), float32),\n",
       " 'target_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32),\n",
       " 'thermal_limit': Box(0.0, inf, (20,), float32),\n",
       " 'theta_ex': Box(-180.0, 180.0, (20,), float32),\n",
       " 'theta_or': Box(-180.0, 180.0, (20,), float32),\n",
       " 'time_before_cooldown_line': Box(0, 10, (20,), int32),\n",
       " 'time_before_cooldown_sub': Box(0, 0, (14,), int32),\n",
       " 'time_next_maintenance': Box(-1, 2147483647, (20,), int32),\n",
       " 'time_since_last_alarm': Box(-1, 2147483647, (1,), int32),\n",
       " 'timestep_overflow': Box(-2147483648, 2147483647, (20,), int32),\n",
       " 'topo_vect': Box(-1, 2, (57,), int32),\n",
       " 'v_ex': Box(0.0, inf, (20,), float32),\n",
       " 'v_or': Box(0.0, inf, (20,), float32),\n",
       " 'was_alarm_used_after_game_over': Discrete(2),\n",
       " 'year': Discrete(2100)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_gym.observation_space.spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep only the information about the flow on the powerlines: `rho`, the generation `gen_p`, the load `load_p` and the representation of the topology `topo_vect` (for the sake of the example, once again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new size of the observation space is : 100 (it was 536 before!)\n"
     ]
    }
   ],
   "source": [
    "env_gym.observation_space = env_gym.observation_space.keep_only_attr([\"rho\", \"gen_p\", \"load_p\", \"topo_vect\", \n",
    "                                                                      \"actual_dispatch\"])\n",
    "new_dim_obs_space = np.sum([np.sum(env_gym.observation_space[el].shape).astype(int) \n",
    "                        for el in env_gym.observation_space.spaces])\n",
    "print(f\"The new size of the observation space is : \"\n",
    "      f\"{new_dim_obs_space} (it was {dim_obs_space} before!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actual_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32),\n",
       " 'gen_p': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32),\n",
       " 'load_p': Box(-inf, inf, (11,), float32),\n",
       " 'rho': Box(0.0, inf, (20,), float32),\n",
       " 'topo_vect': Box(-1, 2, (57,), int32)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_gym.observation_space.spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other detail here, the generation and loads are not scaled (they are given in MW). We recommend to scale them to have number roughly between 0 and 1 for stability during learning.\n",
    "\n",
    "This can be done pretty easily with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\gymnasium\\spaces\\box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\gymnasium\\spaces\\box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict('actual_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32), 'gen_p': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32), 'load_p': Box(-inf, inf, (11,), float32), 'rho': Box(0.0, inf, (20,), float32), 'topo_vect': Box(-1, 2, (57,), int32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from grid2op.gym_compat import ScalerAttrConverter\n",
    "from gymnasium.spaces import Box\n",
    "ob_space = env_gym.observation_space\n",
    "ob_space = ob_space.reencode_space(\"actual_dispatch\",\n",
    "                                   ScalerAttrConverter(substract=0.,\n",
    "                                                       divide=env_glop.gen_pmax\n",
    "                                                       )\n",
    "                                   )\n",
    "ob_space = ob_space.reencode_space(\"gen_p\",\n",
    "                                   ScalerAttrConverter(substract=0.,\n",
    "                                                       divide=env_glop.gen_pmax\n",
    "                                                       )\n",
    "                                   )\n",
    "ob_space = ob_space.reencode_space(\"load_p\",\n",
    "                                  ScalerAttrConverter(substract=obs_gym[\"load_p\"],\n",
    "                                                      divide=0.5 * obs_gym[\"load_p\"]\n",
    "                                                      )\n",
    "                                  )\n",
    "\n",
    "# for even more customization, you can use any functions you want !\n",
    "shape_ = (env_glop.dim_topo, env_glop.dim_topo)\n",
    "env_gym.observation_space.add_key(\"connectivity_matrix\",\n",
    "                                  lambda obs: obs.connectivity_matrix(),  # can be any function returning a gym space\n",
    "                                  Box(shape=shape_,\n",
    "                                      low=np.zeros(shape_),\n",
    "                                      high=np.ones(shape_),\n",
    "                                    )  # this \"Box\" should represent the return type of the above function\n",
    "                                  )\n",
    "env_gym.observation_space = ob_space\n",
    "env_gym.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actual_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32),\n",
       " 'gen_p': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32),\n",
       " 'load_p': Box(-inf, inf, (11,), float32),\n",
       " 'rho': Box(0.0, inf, (20,), float32),\n",
       " 'topo_vect': Box(-1, 2, (57,), int32)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_gym.observation_space.spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Space for actual_dispatch:\n",
      "Type: <class 'gymnasium.spaces.box.Box'>\n",
      "Structure: Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32)\n",
      "\n",
      "Space for gen_p:\n",
      "Type: <class 'gymnasium.spaces.box.Box'>\n",
      "Structure: Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32)\n",
      "\n",
      "Space for load_p:\n",
      "Type: <class 'gymnasium.spaces.box.Box'>\n",
      "Structure: Box(-inf, inf, (11,), float32)\n"
     ]
    }
   ],
   "source": [
    "for key in [\"actual_dispatch\", \"gen_p\", \"load_p\"]:\n",
    "    space = env_gym.observation_space[key]\n",
    "    print(f\"\\nSpace for {key}:\")\n",
    "    print(f\"Type: {type(space)}\")\n",
    "    print(f\"Structure: {space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_dispatch is Box space: True\n",
      "gen_p is Box space: True\n",
      "load_p is Box space: True\n"
     ]
    }
   ],
   "source": [
    "from gymnasium.spaces import Box\n",
    "\n",
    "for key in [\"actual_dispatch\", \"gen_p\", \"load_p\"]:\n",
    "    space = env_gym.observation_space[key]\n",
    "    is_box = isinstance(space, Box)\n",
    "    print(f\"{key} is Box space: {is_box}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"env_gym\" is a gym environment: True\n",
      "\n",
      "Initial shapes:\n",
      "gen_pmax shape: (6,)\n",
      "actual_dispatch shape: (6,)\n",
      "gen_p shape: (6,)\n",
      "load_p shape: (11,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\gymnasium\\spaces\\box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\gymnasium\\spaces\\box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "from grid2op.gym_compat import GymEnv, ScalerAttrConverter\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "# Initialize the environment\n",
    "env_gym = GymEnv(env_glop)\n",
    "\n",
    "# Verify initialization\n",
    "print(f\"The \\\"env_gym\\\" is a gym environment: {isinstance(env_gym, gymnasium.Env)}\")\n",
    "\n",
    "# Get initial observation\n",
    "obs_gym, info = env_gym.reset()\n",
    "\n",
    "# Print some diagnostic information\n",
    "print(\"\\nInitial shapes:\")\n",
    "print(f\"gen_pmax shape: {env_glop.gen_pmax.shape}\")\n",
    "print(f\"actual_dispatch shape: {obs_gym['actual_dispatch'].shape}\")\n",
    "print(f\"gen_p shape: {obs_gym['gen_p'].shape}\")\n",
    "print(f\"load_p shape: {obs_gym['load_p'].shape}\")\n",
    "\n",
    "env_gym.observation_space = env_gym.observation_space.keep_only_attr([\"rho\", \"gen_p\", \"load_p\", \"topo_vect\", \n",
    "                                                                      \"actual_dispatch\"])\n",
    "\n",
    "# Now try the scaling\n",
    "ob_space = env_gym.observation_space\n",
    "\n",
    "# Make sure gen_pmax is the right shape and non-zero\n",
    "gen_pmax = np.maximum(env_glop.gen_pmax, 1e-6)  # Avoid division by zero\n",
    "\n",
    "# Scale actual_dispatch\n",
    "ob_space = ob_space.reencode_space(\n",
    "    \"actual_dispatch\",\n",
    "    ScalerAttrConverter(\n",
    "        substract=np.zeros_like(obs_gym[\"actual_dispatch\"]),\n",
    "        divide=gen_pmax\n",
    "    )\n",
    ")\n",
    "\n",
    "# Scale gen_p\n",
    "ob_space = ob_space.reencode_space(\n",
    "    \"gen_p\",\n",
    "    ScalerAttrConverter(\n",
    "        substract=np.zeros_like(obs_gym[\"gen_p\"]),\n",
    "        divide=gen_pmax\n",
    "    )\n",
    ")\n",
    "\n",
    "# Scale load_p\n",
    "load_p_divide = np.maximum(0.5 * obs_gym[\"load_p\"], 1e-6)\n",
    "ob_space = ob_space.reencode_space(\n",
    "    \"load_p\",\n",
    "    ScalerAttrConverter(\n",
    "        substract=obs_gym[\"load_p\"],\n",
    "        divide=load_p_divide\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add connectivity matrix\n",
    "shape_ = (env_glop.dim_topo, env_glop.dim_topo)\n",
    "ob_space.add_key(\n",
    "    \"connectivity_matrix\",\n",
    "    lambda obs: obs.connectivity_matrix(),\n",
    "    Box(\n",
    "        shape=shape_,\n",
    "        low=np.zeros(shape_),\n",
    "        high=np.ones(shape_),\n",
    "        dtype=np.float32\n",
    "    )\n",
    ")\n",
    "\n",
    "# Assign the modified space back to the environment\n",
    "env_gym.observation_space = ob_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actual_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32),\n",
       " 'gen_p': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32),\n",
       " 'load_p': Box(-inf, inf, (11,), float32),\n",
       " 'rho': Box(0.0, inf, (20,), float32),\n",
       " 'topo_vect': Box(-1, 2, (57,), int32),\n",
       " 'connectivity_matrix': Box(0.0, 1.0, (57, 57), float32)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_gym.observation_space.spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op\n",
    "from grid2op.gym_compat import GymEnv\n",
    "from grid2op.gym_compat import ScalerAttrConverter\n",
    "\n",
    "env_name = \"l2rpn_case14_sandbox\"  # or any other grid2op environment name\n",
    "g2op_env = grid2op.make(env_name)  # create the gri2op environment\n",
    "\n",
    "gym_env = GymEnv(g2op_env)  # create the gymnasium environment\n",
    "\n",
    "\n",
    "gym_env.observation_space = gym_env.observation_space.keep_only_attr([\n",
    "                                                                      \"actual_dispatch\"])\n",
    "\n",
    "\n",
    "ob_space = gym_env.observation_space\n",
    "ob_space = ob_space.reencode_space(\"actual_dispatch\",\n",
    "                                   ScalerAttrConverter(substract=0.8,\n",
    "                                                       divide=env.gen_pmax,\n",
    "                                                       init_space=ob_space[\"actual_dispatch\"]\n",
    "                                                       )\n",
    "                                   )\n",
    "\n",
    "gym_env.observation_space = ob_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('actual_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym_env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\grid2op\\MakeEnv\\Make.py:454: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'actual_dispatch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scaled_obs\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Get scaled observation\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m scaled_obs \u001b[38;5;241m=\u001b[39m \u001b[43mscale_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_glop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_glop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Print some values to verify scaling\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mScaling verification:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 38\u001b[0m, in \u001b[0;36mscale_observation\u001b[1;34m(obs, env)\u001b[0m\n\u001b[0;32m     35\u001b[0m scaled_obs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Scale generator-related observations\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m scaled_obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_dispatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mobs_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mactual_dispatch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m env\u001b[38;5;241m.\u001b[39mgen_pmax\n\u001b[0;32m     39\u001b[0m scaled_obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgen_p\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgen_p\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m env\u001b[38;5;241m.\u001b[39mgen_pmax\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Scale load-related observations\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Using mean load as reference to avoid division by zero\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'actual_dispatch'"
     ]
    }
   ],
   "source": [
    "import grid2op\n",
    "import numpy as np\n",
    "\n",
    "# Try to use LightSimBackend, fall back to PandaPowerBackend if not available\n",
    "try:\n",
    "    from lightsim2grid import LightSimBackend\n",
    "    bk_cls = LightSimBackend\n",
    "except ImportError as exc:\n",
    "    print(f\"Error: {exc} when importing faster LightSimBackend\")\n",
    "    from grid2op.Backend import PandaPowerBackend\n",
    "    bk_cls = PandaPowerBackend\n",
    "    \n",
    "# Create the environment\n",
    "env_name = \"l2rpn_case14_sandbox\"\n",
    "env_glop = grid2op.make(env_name, test=True, backend=bk_cls())\n",
    "\n",
    "# Get initial observation\n",
    "obs_glop = env_glop.reset()\n",
    "\n",
    "def scale_observation(obs, env):\n",
    "    \"\"\"\n",
    "    Scale the observation values to a normalized range.\n",
    "    \n",
    "    Args:\n",
    "        obs: Grid2Op observation\n",
    "        env: Grid2Op environment\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing scaled observation values\n",
    "    \"\"\"\n",
    "    # Convert Grid2Op observation to dictionary\n",
    "    obs_dict = obs.to_dict()\n",
    "    \n",
    "    # Create scaled dictionary\n",
    "    scaled_obs = {}\n",
    "    \n",
    "    # Scale generator-related observations\n",
    "    scaled_obs[\"actual_dispatch\"] = obs_dict[\"actual_dispatch\"] / env.gen_pmax\n",
    "    scaled_obs[\"gen_p\"] = obs_dict[\"gen_p\"] / env.gen_pmax\n",
    "    \n",
    "    # Scale load-related observations\n",
    "    # Using mean load as reference to avoid division by zero\n",
    "    load_p = obs_dict[\"load_p\"]\n",
    "    load_ref = np.maximum(0.5 * load_p, 1e-6)  # avoid division by zero\n",
    "    scaled_obs[\"load_p\"] = (load_p - load_p.mean()) / load_ref\n",
    "    \n",
    "    # Add other observations you might need (unscaled)\n",
    "    scaled_obs[\"rho\"] = obs_dict[\"rho\"]  # line usage\n",
    "    scaled_obs[\"line_status\"] = obs_dict[\"line_status\"]\n",
    "    scaled_obs[\"topo_vect\"] = obs_dict[\"topo_vect\"]\n",
    "    \n",
    "    return scaled_obs\n",
    "\n",
    "# Get scaled observation\n",
    "scaled_obs = scale_observation(obs_glop, env_glop)\n",
    "\n",
    "# Print some values to verify scaling\n",
    "print(\"\\nScaling verification:\")\n",
    "print(f\"Original gen_p range: [{obs_glop.gen_p.min():.2f}, {obs_glop.gen_p.max():.2f}]\")\n",
    "print(f\"Scaled gen_p range: [{scaled_obs['gen_p'].min():.2f}, {scaled_obs['gen_p'].max():.2f}]\")\n",
    "print(f\"\\nOriginal load_p range: [{obs_glop.load_p.min():.2f}, {obs_glop.load_p.max():.2f}]\")\n",
    "print(f\"Scaled load_p range: [{scaled_obs['load_p'].min():.2f}, {scaled_obs['load_p'].max():.2f}]\")\n",
    "\n",
    "# You can now use scaled_obs in your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Grid2Op\\venv_g2op\\lib\\site-packages\\grid2op\\MakeEnv\\Make.py:454: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"env_gym\" is a gym environment: True\n"
     ]
    }
   ],
   "source": [
    "env_name = \"l2rpn_case14_sandbox\"\n",
    "env_glop = grid2op.make(env_name, test=True, backend=bk_cls())\n",
    "# NOTE: do not set the flag \"test=True\" for a real usage !\n",
    "# NOTE: use grid2op.make(env_name+\"_train\", test=True) for a real usage (see paragraph above !)\n",
    "\n",
    "# This flag is here for testing purpose !!!\n",
    "obs_glop = env_glop.reset()\n",
    "# obs_glop\n",
    "\n",
    "import gymnasium\n",
    "import numpy as np\n",
    "from grid2op.gym_compat import GymEnv\n",
    "env_gym_init = GymEnv(env_glop)\n",
    "env_gym = GymEnv(env_glop)\n",
    "print(f\"The \\\"env_gym\\\" is a gym environment: {isinstance(env_gym, gymnasium.Env)}\")\n",
    "obs_gym, info = env_gym.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('_shunt_bus', array([1])),\n",
       "             ('_shunt_p', array([-3.469447e-16], dtype=float32)),\n",
       "             ('_shunt_q', array([-21.122274], dtype=float32)),\n",
       "             ('_shunt_v', array([21.087423], dtype=float32)),\n",
       "             ('a_ex',\n",
       "              array([ 155.4294  ,  127.13096 ,  102.944534,  138.83089 ,  108.19038 ,\n",
       "                       52.725002,  135.8066  ,  434.52097 ,  252.7422  ,  649.2642  ,\n",
       "                       56.01385 ,  183.57965 ,  324.49686 ,   79.42569 ,  319.6616  ,\n",
       "                      970.70337 ,  312.82553 ,  475.6461  , 1045.0125  ,  804.76953 ],\n",
       "                    dtype=float32)),\n",
       "             ('a_or',\n",
       "              array([162.49808 , 127.40141 , 107.29365 , 138.40088 , 107.903015,\n",
       "                      48.582985, 135.8066  , 434.52097 , 252.7422  , 649.2642  ,\n",
       "                      56.01385 , 183.57965 , 324.49686 ,  79.42569 , 319.6616  ,\n",
       "                     100.69238 ,  46.78745 ,  73.963745, 895.725   , 563.3386  ],\n",
       "                    dtype=float32)),\n",
       "             ('actual_dispatch',\n",
       "              array([0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       "             ('attention_budget', array([0.], dtype=float32)),\n",
       "             ('current_step', array([0])),\n",
       "             ('curtailment', array([0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       "             ('curtailment_limit',\n",
       "              array([1., 1., 1., 1., 1., 1.], dtype=float32)),\n",
       "             ('curtailment_limit_effective',\n",
       "              array([1., 1., 1., 1., 1., 1.], dtype=float32)),\n",
       "             ('day', 6),\n",
       "             ('day_of_week', 6),\n",
       "             ('delta_time', array([5.], dtype=float32)),\n",
       "             ('duration_next_maintenance',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('gen_margin_down',\n",
       "              array([ 5., 10.,  0.,  0.,  0., 15.], dtype=float32)),\n",
       "             ('gen_margin_up',\n",
       "              array([ 5., 10.,  0.,  0.,  0., 15.], dtype=float32)),\n",
       "             ('gen_p',\n",
       "              array([70.6    , 68.7    , 37.     ,  0.     ,  0.     , 68.55669],\n",
       "                    dtype=float32)),\n",
       "             ('gen_p_before_curtail',\n",
       "              array([ 0.,  0., 37.,  0.,  0.,  0.], dtype=float32)),\n",
       "             ('gen_q',\n",
       "              array([ 16.778887,  73.482414,  20.676498,  20.676498,  23.892193,\n",
       "                     -16.489828], dtype=float32)),\n",
       "             ('gen_theta',\n",
       "              array([-1.3143696, -4.154612 , -5.8972316, -5.8972316, -6.687735 ,\n",
       "                      0.       ], dtype=float32)),\n",
       "             ('gen_v',\n",
       "              array([142.1     , 142.1     ,  22.      ,  22.      ,  13.200001,\n",
       "                     142.1     ], dtype=float32)),\n",
       "             ('hour_of_day', 0),\n",
       "             ('is_alarm_illegal', 0),\n",
       "             ('line_status',\n",
       "              array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                      True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                      True,  True])),\n",
       "             ('load_p',\n",
       "              array([21.7, 85.6, 43.6,  6.9, 11.6, 27.9,  8.6,  3.4,  5.3, 12.3, 14.6],\n",
       "                    dtype=float32)),\n",
       "             ('load_q',\n",
       "              array([15.2, 60.4, 30.9,  4.8,  8.1, 19.5,  6.1,  2.3,  3.8,  8.9, 10.2],\n",
       "                    dtype=float32)),\n",
       "             ('load_theta',\n",
       "              array([-1.3143696, -4.154612 , -4.565471 , -3.8133612, -5.8972316,\n",
       "                     -7.7796664, -7.6845007, -6.8852997, -6.590787 , -6.7289248,\n",
       "                     -8.084337 ], dtype=float32)),\n",
       "             ('load_v',\n",
       "              array([142.1     , 142.1     , 139.20154 , 139.94933 ,  22.      ,\n",
       "                      21.087423,  21.088373,  21.452332,  21.578804,  21.423275,\n",
       "                      20.72405 ], dtype=float32)),\n",
       "             ('max_step', array([575])),\n",
       "             ('minute_of_hour', 0),\n",
       "             ('month', 1),\n",
       "             ('p_ex',\n",
       "              array([-3.69823456e+01, -3.07961235e+01, -2.49757748e+01, -3.34252586e+01,\n",
       "                     -2.61683636e+01, -7.97755718e+00,  3.27947464e+01, -1.40378275e+01,\n",
       "                     -8.01669121e+00, -1.99711876e+01,  1.93415070e+00, -4.43844032e+00,\n",
       "                      1.06378279e+01, -2.69996762e+00, -1.01615601e+01, -1.93921547e+01,\n",
       "                     -1.10647383e+01, -1.72697411e+01,  7.63278329e-15,  1.93921547e+01],\n",
       "                    dtype=float32)),\n",
       "             ('p_or',\n",
       "              array([ 3.7261272e+01,  3.1295414e+01,  2.5271448e+01,  3.4063332e+01,\n",
       "                      2.6547562e+01,  8.0757742e+00, -3.2654076e+01,  1.4253024e+01,\n",
       "                      8.1109076e+00,  2.0305809e+01, -1.9329531e+00,  4.4898458e+00,\n",
       "                     -1.0534151e+01,  2.7166915e+00,  1.0371155e+01,  1.9392155e+01,\n",
       "                      1.1064738e+01,  1.7269741e+01, -7.2858386e-15, -1.9392155e+01],\n",
       "                    dtype=float32)),\n",
       "             ('q_ex',\n",
       "              array([  9.785145 ,  -1.1193229,   4.264093 ,  -1.7814633,  -1.7267758,\n",
       "                      -9.897425 ,   2.8623838,  -7.9755735,  -4.996689 , -13.474534 ,\n",
       "                      -0.667122 ,  -4.8706503,   5.6755733,  -1.1815578,  -5.3293495,\n",
       "                      15.764592 ,   2.8496184,   5.500487 ,  23.892193 ,   7.2965856],\n",
       "                    dtype=float32)),\n",
       "             ('q_or',\n",
       "              array([-14.53193   ,  -1.9578984 ,  -7.6625476 ,   0.18529181,\n",
       "                      -0.72900116,   8.818317  ,  -2.4186666 ,   8.426222  ,\n",
       "                       5.1927786 ,  14.133509  ,   0.67030346,   4.9799967 ,\n",
       "                      -5.432878  ,   1.196689  ,   5.7560925 , -14.605959  ,\n",
       "                      -2.1964862 ,  -4.816285  , -23.061178  ,  -6.8776445 ],\n",
       "                    dtype=float32)),\n",
       "             ('rho',\n",
       "              array([0.30036613, 0.28311425, 0.2861164 , 0.21761145, 0.61658865,\n",
       "                     0.17046662, 0.40539283, 0.66137135, 0.5095609 , 0.7850837 ,\n",
       "                     0.12672818, 0.2863957 , 0.38630578, 0.50913906, 0.48141804,\n",
       "                     0.4284782 , 0.39317185, 0.41320527, 0.45101961, 0.3583579 ],\n",
       "                    dtype=float32)),\n",
       "             ('target_dispatch',\n",
       "              array([0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       "             ('thermal_limit',\n",
       "              array([ 541.,  450.,  375.,  636.,  175.,  285.,  335.,  657.,  496.,\n",
       "                      827.,  442.,  641.,  840.,  156.,  664.,  235.,  119.,  179.,\n",
       "                     1986., 1572.], dtype=float32)),\n",
       "             ('theta_ex',\n",
       "              array([-1.3143696, -3.8133612, -4.154612 , -4.565471 , -3.8133612,\n",
       "                     -4.565471 , -3.8133612, -6.8852997, -6.590787 , -6.7289248,\n",
       "                     -7.6845007, -8.084337 , -6.8852997, -6.7289248, -8.084337 ,\n",
       "                     -6.687735 , -7.7796664, -5.8972316, -6.687735 , -6.687735 ],\n",
       "                    dtype=float32)),\n",
       "             ('theta_or',\n",
       "              array([ 0.       ,  0.       , -1.3143696, -1.3143696, -1.3143696,\n",
       "                     -4.154612 , -4.565471 , -5.8972316, -5.8972316, -5.8972316,\n",
       "                     -7.7796664, -7.7796664, -7.6845007, -6.590787 , -6.7289248,\n",
       "                     -4.565471 , -4.565471 , -3.8133612, -6.687735 , -7.7796664],\n",
       "                    dtype=float32)),\n",
       "             ('time_before_cooldown_line',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('time_before_cooldown_sub',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('time_next_maintenance',\n",
       "              array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                     -1, -1, -1])),\n",
       "             ('time_since_last_alarm', array([-1])),\n",
       "             ('timestep_overflow',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('topo_vect',\n",
       "              array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])),\n",
       "             ('v_ex',\n",
       "              array([142.1     , 139.94933 , 142.1     , 139.20154 , 139.94933 ,\n",
       "                     139.20154 , 139.94933 ,  21.452332,  21.578804,  21.423275,\n",
       "                      21.088373,  20.72405 ,  21.452332,  21.423275,  20.72405 ,\n",
       "                      14.864359,  21.087423,  22.      ,  13.200001,  14.864359],\n",
       "                    dtype=float32)),\n",
       "             ('v_or',\n",
       "              array([142.1     , 142.1     , 142.1     , 142.1     , 142.1     ,\n",
       "                     142.1     , 139.20154 ,  22.      ,  22.      ,  22.      ,\n",
       "                      21.087423,  21.087423,  21.088373,  21.578804,  21.423275,\n",
       "                     139.20154 , 139.20154 , 139.94933 ,  14.864359,  21.087423],\n",
       "                    dtype=float32)),\n",
       "             ('was_alarm_used_after_game_over', 0),\n",
       "             ('year', 2019)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw observation\n",
    "obs_gym, info = env_gym.reset()\n",
    "\n",
    "# Scale actual_dispatch\n",
    "scaled_dispatch = obs_gym[\"actual_dispatch\"] / env_glop.gen_pmax\n",
    "\n",
    "# Scale gen_p \n",
    "scaled_gen_p = obs_gym[\"gen_p\"] / env_glop.gen_pmax\n",
    "\n",
    "# Scale load_p\n",
    "scaled_load_p = (obs_gym[\"load_p\"] - obs_gym[\"load_p\"]) / (0.5 * obs_gym[\"load_p\"])\n",
    "\n",
    "''' \n",
    "# Create a new dictionary with scaled values\n",
    "\n",
    "scaled_obs[\"actual_dispatch\"] = scaled_dispatch\n",
    "scaled_obs[\"gen_p\"] = scaled_gen_p\n",
    "scaled_obs[\"load_p\"] = scaled_load_p\n",
    "\n",
    "''' \n",
    "\n",
    "''' \n",
    "scaled_obs[\"actual_dispatch\"] = np.copy(scaled_dispatch)\n",
    "scaled_obs[\"gen_p\"] = np.copy(scaled_gen_p)\n",
    "scaled_obs[\"load_p\"] = np.copy(scaled_load_p)\n",
    "'''\n",
    "scaled_obs = obs_gym.copy()  # if .copy() is removed, obs_gym and scaled_obs and evrthing nested inside will always point to the same objects, which means they're always the same\n",
    "\n",
    "#scaled_obs = obs_gym\n",
    "\n",
    "# Manually copy NumPy arrays to break the memory link\n",
    "\n",
    "scaled_obs[\"actual_dispatch\"] = scaled_dispatch\n",
    "scaled_obs[\"gen_p\"] = scaled_gen_p\n",
    "scaled_obs[\"load_p\"] = scaled_load_p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.may_share_memory(obs_gym[\"a_ex\"], scaled_obs[\"a_ex\"]))  # True  they share memory\n",
    "print(np.may_share_memory(obs_gym[\"gen_p\"], scaled_obs[\"gen_p\"]))  # False  they don't share memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('_shunt_bus', array([1])),\n",
       "             ('_shunt_p', array([-3.469447e-16], dtype=float32)),\n",
       "             ('_shunt_q', array([-21.122274], dtype=float32)),\n",
       "             ('_shunt_v', array([21.087423], dtype=float32)),\n",
       "             ('a_ex',\n",
       "              array([ 155.4294  ,  127.13096 ,  102.944534,  138.83089 ,  108.19038 ,\n",
       "                       52.725002,  135.8066  ,  434.52097 ,  252.7422  ,  649.2642  ,\n",
       "                       56.01385 ,  183.57965 ,  324.49686 ,   79.42569 ,  319.6616  ,\n",
       "                      970.70337 ,  312.82553 ,  475.6461  , 1045.0125  ,  804.76953 ],\n",
       "                    dtype=float32)),\n",
       "             ('a_or',\n",
       "              array([162.49808 , 127.40141 , 107.29365 , 138.40088 , 107.903015,\n",
       "                      48.582985, 135.8066  , 434.52097 , 252.7422  , 649.2642  ,\n",
       "                      56.01385 , 183.57965 , 324.49686 ,  79.42569 , 319.6616  ,\n",
       "                     100.69238 ,  46.78745 ,  73.963745, 895.725   , 563.3386  ],\n",
       "                    dtype=float32)),\n",
       "             ('actual_dispatch',\n",
       "              array([0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       "             ('attention_budget', array([0.], dtype=float32)),\n",
       "             ('current_step', array([0])),\n",
       "             ('curtailment', array([0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       "             ('curtailment_limit',\n",
       "              array([1., 1., 1., 1., 1., 1.], dtype=float32)),\n",
       "             ('curtailment_limit_effective',\n",
       "              array([1., 1., 1., 1., 1., 1.], dtype=float32)),\n",
       "             ('day', 6),\n",
       "             ('day_of_week', 6),\n",
       "             ('delta_time', array([5.], dtype=float32)),\n",
       "             ('duration_next_maintenance',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('gen_margin_down',\n",
       "              array([ 5., 10.,  0.,  0.,  0., 15.], dtype=float32)),\n",
       "             ('gen_margin_up',\n",
       "              array([ 5., 10.,  0.,  0.,  0., 15.], dtype=float32)),\n",
       "             ('gen_p',\n",
       "              array([0.5042857 , 0.5725    , 0.5285714 , 0.        , 0.        ,\n",
       "                     0.68556684], dtype=float32)),\n",
       "             ('gen_p_before_curtail',\n",
       "              array([ 0.,  0., 37.,  0.,  0.,  0.], dtype=float32)),\n",
       "             ('gen_q',\n",
       "              array([ 16.778887,  73.482414,  20.676498,  20.676498,  23.892193,\n",
       "                     -16.489828], dtype=float32)),\n",
       "             ('gen_theta',\n",
       "              array([-1.3143696, -4.154612 , -5.8972316, -5.8972316, -6.687735 ,\n",
       "                      0.       ], dtype=float32)),\n",
       "             ('gen_v',\n",
       "              array([142.1     , 142.1     ,  22.      ,  22.      ,  13.200001,\n",
       "                     142.1     ], dtype=float32)),\n",
       "             ('hour_of_day', 0),\n",
       "             ('is_alarm_illegal', 0),\n",
       "             ('line_status',\n",
       "              array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                      True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                      True,  True])),\n",
       "             ('load_p',\n",
       "              array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       "             ('load_q',\n",
       "              array([15.2, 60.4, 30.9,  4.8,  8.1, 19.5,  6.1,  2.3,  3.8,  8.9, 10.2],\n",
       "                    dtype=float32)),\n",
       "             ('load_theta',\n",
       "              array([-1.3143696, -4.154612 , -4.565471 , -3.8133612, -5.8972316,\n",
       "                     -7.7796664, -7.6845007, -6.8852997, -6.590787 , -6.7289248,\n",
       "                     -8.084337 ], dtype=float32)),\n",
       "             ('load_v',\n",
       "              array([142.1     , 142.1     , 139.20154 , 139.94933 ,  22.      ,\n",
       "                      21.087423,  21.088373,  21.452332,  21.578804,  21.423275,\n",
       "                      20.72405 ], dtype=float32)),\n",
       "             ('max_step', array([575])),\n",
       "             ('minute_of_hour', 0),\n",
       "             ('month', 1),\n",
       "             ('p_ex',\n",
       "              array([-3.69823456e+01, -3.07961235e+01, -2.49757748e+01, -3.34252586e+01,\n",
       "                     -2.61683636e+01, -7.97755718e+00,  3.27947464e+01, -1.40378275e+01,\n",
       "                     -8.01669121e+00, -1.99711876e+01,  1.93415070e+00, -4.43844032e+00,\n",
       "                      1.06378279e+01, -2.69996762e+00, -1.01615601e+01, -1.93921547e+01,\n",
       "                     -1.10647383e+01, -1.72697411e+01,  7.63278329e-15,  1.93921547e+01],\n",
       "                    dtype=float32)),\n",
       "             ('p_or',\n",
       "              array([ 3.7261272e+01,  3.1295414e+01,  2.5271448e+01,  3.4063332e+01,\n",
       "                      2.6547562e+01,  8.0757742e+00, -3.2654076e+01,  1.4253024e+01,\n",
       "                      8.1109076e+00,  2.0305809e+01, -1.9329531e+00,  4.4898458e+00,\n",
       "                     -1.0534151e+01,  2.7166915e+00,  1.0371155e+01,  1.9392155e+01,\n",
       "                      1.1064738e+01,  1.7269741e+01, -7.2858386e-15, -1.9392155e+01],\n",
       "                    dtype=float32)),\n",
       "             ('q_ex',\n",
       "              array([  9.785145 ,  -1.1193229,   4.264093 ,  -1.7814633,  -1.7267758,\n",
       "                      -9.897425 ,   2.8623838,  -7.9755735,  -4.996689 , -13.474534 ,\n",
       "                      -0.667122 ,  -4.8706503,   5.6755733,  -1.1815578,  -5.3293495,\n",
       "                      15.764592 ,   2.8496184,   5.500487 ,  23.892193 ,   7.2965856],\n",
       "                    dtype=float32)),\n",
       "             ('q_or',\n",
       "              array([-14.53193   ,  -1.9578984 ,  -7.6625476 ,   0.18529181,\n",
       "                      -0.72900116,   8.818317  ,  -2.4186666 ,   8.426222  ,\n",
       "                       5.1927786 ,  14.133509  ,   0.67030346,   4.9799967 ,\n",
       "                      -5.432878  ,   1.196689  ,   5.7560925 , -14.605959  ,\n",
       "                      -2.1964862 ,  -4.816285  , -23.061178  ,  -6.8776445 ],\n",
       "                    dtype=float32)),\n",
       "             ('rho',\n",
       "              array([0.30036613, 0.28311425, 0.2861164 , 0.21761145, 0.61658865,\n",
       "                     0.17046662, 0.40539283, 0.66137135, 0.5095609 , 0.7850837 ,\n",
       "                     0.12672818, 0.2863957 , 0.38630578, 0.50913906, 0.48141804,\n",
       "                     0.4284782 , 0.39317185, 0.41320527, 0.45101961, 0.3583579 ],\n",
       "                    dtype=float32)),\n",
       "             ('target_dispatch',\n",
       "              array([0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       "             ('thermal_limit',\n",
       "              array([ 541.,  450.,  375.,  636.,  175.,  285.,  335.,  657.,  496.,\n",
       "                      827.,  442.,  641.,  840.,  156.,  664.,  235.,  119.,  179.,\n",
       "                     1986., 1572.], dtype=float32)),\n",
       "             ('theta_ex',\n",
       "              array([-1.3143696, -3.8133612, -4.154612 , -4.565471 , -3.8133612,\n",
       "                     -4.565471 , -3.8133612, -6.8852997, -6.590787 , -6.7289248,\n",
       "                     -7.6845007, -8.084337 , -6.8852997, -6.7289248, -8.084337 ,\n",
       "                     -6.687735 , -7.7796664, -5.8972316, -6.687735 , -6.687735 ],\n",
       "                    dtype=float32)),\n",
       "             ('theta_or',\n",
       "              array([ 0.       ,  0.       , -1.3143696, -1.3143696, -1.3143696,\n",
       "                     -4.154612 , -4.565471 , -5.8972316, -5.8972316, -5.8972316,\n",
       "                     -7.7796664, -7.7796664, -7.6845007, -6.590787 , -6.7289248,\n",
       "                     -4.565471 , -4.565471 , -3.8133612, -6.687735 , -7.7796664],\n",
       "                    dtype=float32)),\n",
       "             ('time_before_cooldown_line',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('time_before_cooldown_sub',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('time_next_maintenance',\n",
       "              array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                     -1, -1, -1])),\n",
       "             ('time_since_last_alarm', array([-1])),\n",
       "             ('timestep_overflow',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('topo_vect',\n",
       "              array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])),\n",
       "             ('v_ex',\n",
       "              array([142.1     , 139.94933 , 142.1     , 139.20154 , 139.94933 ,\n",
       "                     139.20154 , 139.94933 ,  21.452332,  21.578804,  21.423275,\n",
       "                      21.088373,  20.72405 ,  21.452332,  21.423275,  20.72405 ,\n",
       "                      14.864359,  21.087423,  22.      ,  13.200001,  14.864359],\n",
       "                    dtype=float32)),\n",
       "             ('v_or',\n",
       "              array([142.1     , 142.1     , 142.1     , 142.1     , 142.1     ,\n",
       "                     142.1     , 139.20154 ,  22.      ,  22.      ,  22.      ,\n",
       "                      21.087423,  21.087423,  21.088373,  21.578804,  21.423275,\n",
       "                     139.20154 , 139.20154 , 139.94933 ,  14.864359,  21.087423],\n",
       "                    dtype=float32)),\n",
       "             ('was_alarm_used_after_game_over', 0),\n",
       "             ('year', 2019)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('_shunt_bus', array([1])),\n",
       "             ('_shunt_p', array([-3.469447e-16], dtype=float32)),\n",
       "             ('_shunt_q', array([-21.122274], dtype=float32)),\n",
       "             ('_shunt_v', array([21.087423], dtype=float32)),\n",
       "             ('a_ex',\n",
       "              array([ 155.4294  ,  127.13096 ,  102.944534,  138.83089 ,  108.19038 ,\n",
       "                       52.725002,  135.8066  ,  434.52097 ,  252.7422  ,  649.2642  ,\n",
       "                       56.01385 ,  183.57965 ,  324.49686 ,   79.42569 ,  319.6616  ,\n",
       "                      970.70337 ,  312.82553 ,  475.6461  , 1045.0125  ,  804.76953 ],\n",
       "                    dtype=float32)),\n",
       "             ('a_or',\n",
       "              array([162.49808 , 127.40141 , 107.29365 , 138.40088 , 107.903015,\n",
       "                      48.582985, 135.8066  , 434.52097 , 252.7422  , 649.2642  ,\n",
       "                      56.01385 , 183.57965 , 324.49686 ,  79.42569 , 319.6616  ,\n",
       "                     100.69238 ,  46.78745 ,  73.963745, 895.725   , 563.3386  ],\n",
       "                    dtype=float32)),\n",
       "             ('actual_dispatch',\n",
       "              array([0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       "             ('attention_budget', array([0.], dtype=float32)),\n",
       "             ('current_step', array([0])),\n",
       "             ('curtailment', array([0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       "             ('curtailment_limit',\n",
       "              array([1., 1., 1., 1., 1., 1.], dtype=float32)),\n",
       "             ('curtailment_limit_effective',\n",
       "              array([1., 1., 1., 1., 1., 1.], dtype=float32)),\n",
       "             ('day', 6),\n",
       "             ('day_of_week', 6),\n",
       "             ('delta_time', array([5.], dtype=float32)),\n",
       "             ('duration_next_maintenance',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('gen_margin_down',\n",
       "              array([ 5., 10.,  0.,  0.,  0., 15.], dtype=float32)),\n",
       "             ('gen_margin_up',\n",
       "              array([ 5., 10.,  0.,  0.,  0., 15.], dtype=float32)),\n",
       "             ('gen_p',\n",
       "              array([70.6    , 68.7    , 37.     ,  0.     ,  0.     , 68.55669],\n",
       "                    dtype=float32)),\n",
       "             ('gen_p_before_curtail',\n",
       "              array([ 0.,  0., 37.,  0.,  0.,  0.], dtype=float32)),\n",
       "             ('gen_q',\n",
       "              array([ 16.778887,  73.482414,  20.676498,  20.676498,  23.892193,\n",
       "                     -16.489828], dtype=float32)),\n",
       "             ('gen_theta',\n",
       "              array([-1.3143696, -4.154612 , -5.8972316, -5.8972316, -6.687735 ,\n",
       "                      0.       ], dtype=float32)),\n",
       "             ('gen_v',\n",
       "              array([142.1     , 142.1     ,  22.      ,  22.      ,  13.200001,\n",
       "                     142.1     ], dtype=float32)),\n",
       "             ('hour_of_day', 0),\n",
       "             ('is_alarm_illegal', 0),\n",
       "             ('line_status',\n",
       "              array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                      True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                      True,  True])),\n",
       "             ('load_p',\n",
       "              array([21.7, 85.6, 43.6,  6.9, 11.6, 27.9,  8.6,  3.4,  5.3, 12.3, 14.6],\n",
       "                    dtype=float32)),\n",
       "             ('load_q',\n",
       "              array([15.2, 60.4, 30.9,  4.8,  8.1, 19.5,  6.1,  2.3,  3.8,  8.9, 10.2],\n",
       "                    dtype=float32)),\n",
       "             ('load_theta',\n",
       "              array([-1.3143696, -4.154612 , -4.565471 , -3.8133612, -5.8972316,\n",
       "                     -7.7796664, -7.6845007, -6.8852997, -6.590787 , -6.7289248,\n",
       "                     -8.084337 ], dtype=float32)),\n",
       "             ('load_v',\n",
       "              array([142.1     , 142.1     , 139.20154 , 139.94933 ,  22.      ,\n",
       "                      21.087423,  21.088373,  21.452332,  21.578804,  21.423275,\n",
       "                      20.72405 ], dtype=float32)),\n",
       "             ('max_step', array([575])),\n",
       "             ('minute_of_hour', 0),\n",
       "             ('month', 1),\n",
       "             ('p_ex',\n",
       "              array([-3.69823456e+01, -3.07961235e+01, -2.49757748e+01, -3.34252586e+01,\n",
       "                     -2.61683636e+01, -7.97755718e+00,  3.27947464e+01, -1.40378275e+01,\n",
       "                     -8.01669121e+00, -1.99711876e+01,  1.93415070e+00, -4.43844032e+00,\n",
       "                      1.06378279e+01, -2.69996762e+00, -1.01615601e+01, -1.93921547e+01,\n",
       "                     -1.10647383e+01, -1.72697411e+01,  7.63278329e-15,  1.93921547e+01],\n",
       "                    dtype=float32)),\n",
       "             ('p_or',\n",
       "              array([ 3.7261272e+01,  3.1295414e+01,  2.5271448e+01,  3.4063332e+01,\n",
       "                      2.6547562e+01,  8.0757742e+00, -3.2654076e+01,  1.4253024e+01,\n",
       "                      8.1109076e+00,  2.0305809e+01, -1.9329531e+00,  4.4898458e+00,\n",
       "                     -1.0534151e+01,  2.7166915e+00,  1.0371155e+01,  1.9392155e+01,\n",
       "                      1.1064738e+01,  1.7269741e+01, -7.2858386e-15, -1.9392155e+01],\n",
       "                    dtype=float32)),\n",
       "             ('q_ex',\n",
       "              array([  9.785145 ,  -1.1193229,   4.264093 ,  -1.7814633,  -1.7267758,\n",
       "                      -9.897425 ,   2.8623838,  -7.9755735,  -4.996689 , -13.474534 ,\n",
       "                      -0.667122 ,  -4.8706503,   5.6755733,  -1.1815578,  -5.3293495,\n",
       "                      15.764592 ,   2.8496184,   5.500487 ,  23.892193 ,   7.2965856],\n",
       "                    dtype=float32)),\n",
       "             ('q_or',\n",
       "              array([-14.53193   ,  -1.9578984 ,  -7.6625476 ,   0.18529181,\n",
       "                      -0.72900116,   8.818317  ,  -2.4186666 ,   8.426222  ,\n",
       "                       5.1927786 ,  14.133509  ,   0.67030346,   4.9799967 ,\n",
       "                      -5.432878  ,   1.196689  ,   5.7560925 , -14.605959  ,\n",
       "                      -2.1964862 ,  -4.816285  , -23.061178  ,  -6.8776445 ],\n",
       "                    dtype=float32)),\n",
       "             ('rho',\n",
       "              array([0.30036613, 0.28311425, 0.2861164 , 0.21761145, 0.61658865,\n",
       "                     0.17046662, 0.40539283, 0.66137135, 0.5095609 , 0.7850837 ,\n",
       "                     0.12672818, 0.2863957 , 0.38630578, 0.50913906, 0.48141804,\n",
       "                     0.4284782 , 0.39317185, 0.41320527, 0.45101961, 0.3583579 ],\n",
       "                    dtype=float32)),\n",
       "             ('target_dispatch',\n",
       "              array([0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       "             ('thermal_limit',\n",
       "              array([ 541.,  450.,  375.,  636.,  175.,  285.,  335.,  657.,  496.,\n",
       "                      827.,  442.,  641.,  840.,  156.,  664.,  235.,  119.,  179.,\n",
       "                     1986., 1572.], dtype=float32)),\n",
       "             ('theta_ex',\n",
       "              array([-1.3143696, -3.8133612, -4.154612 , -4.565471 , -3.8133612,\n",
       "                     -4.565471 , -3.8133612, -6.8852997, -6.590787 , -6.7289248,\n",
       "                     -7.6845007, -8.084337 , -6.8852997, -6.7289248, -8.084337 ,\n",
       "                     -6.687735 , -7.7796664, -5.8972316, -6.687735 , -6.687735 ],\n",
       "                    dtype=float32)),\n",
       "             ('theta_or',\n",
       "              array([ 0.       ,  0.       , -1.3143696, -1.3143696, -1.3143696,\n",
       "                     -4.154612 , -4.565471 , -5.8972316, -5.8972316, -5.8972316,\n",
       "                     -7.7796664, -7.7796664, -7.6845007, -6.590787 , -6.7289248,\n",
       "                     -4.565471 , -4.565471 , -3.8133612, -6.687735 , -7.7796664],\n",
       "                    dtype=float32)),\n",
       "             ('time_before_cooldown_line',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('time_before_cooldown_sub',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('time_next_maintenance',\n",
       "              array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                     -1, -1, -1])),\n",
       "             ('time_since_last_alarm', array([-1])),\n",
       "             ('timestep_overflow',\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('topo_vect',\n",
       "              array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])),\n",
       "             ('v_ex',\n",
       "              array([142.1     , 139.94933 , 142.1     , 139.20154 , 139.94933 ,\n",
       "                     139.20154 , 139.94933 ,  21.452332,  21.578804,  21.423275,\n",
       "                      21.088373,  20.72405 ,  21.452332,  21.423275,  20.72405 ,\n",
       "                      14.864359,  21.087423,  22.      ,  13.200001,  14.864359],\n",
       "                    dtype=float32)),\n",
       "             ('v_or',\n",
       "              array([142.1     , 142.1     , 142.1     , 142.1     , 142.1     ,\n",
       "                     142.1     , 139.20154 ,  22.      ,  22.      ,  22.      ,\n",
       "                      21.087423,  21.087423,  21.088373,  21.578804,  21.423275,\n",
       "                     139.20154 , 139.20154 , 139.94933 ,  14.864359,  21.087423],\n",
       "                    dtype=float32)),\n",
       "             ('was_alarm_used_after_game_over', 0),\n",
       "             ('year', 2019)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_obs[\"a_ex\"] += 100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100155.43 , 100127.13 , 100102.945, 100138.83 , 100108.19 ,\n",
       "       100052.73 , 100135.805, 100434.52 , 100252.74 , 100649.266,\n",
       "       100056.016, 100183.58 , 100324.5  , 100079.42 , 100319.664,\n",
       "       100970.7  , 100312.83 , 100475.65 , 101045.016, 100804.766],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_gym[\"a_ex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_obs[\"gen_p\"] = scaled_gen_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5042857 , 0.5725    , 0.5285714 , 0.        , 0.        ,\n",
       "       0.68556684], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_gen_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.6    , 68.7    , 37.     ,  0.     ,  0.     , 68.55669],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_gym[\"gen_p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.may_share_memory(obs_gym[\"a_ex\"], scaled_obs[\"a_ex\"]))  # True  they share memory\n",
    "print(np.may_share_memory(obs_gym[\"gen_p\"], scaled_obs[\"gen_p\"]))  # False  they don't share memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1, 2, 3]\n",
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self, data, ss ):\n",
    "        self.data = data\n",
    "        self.ss = ss\n",
    "\n",
    "original = MyClass([1, 2, 3], 3)\n",
    "shallow_copy = copy.deepcopy(original)\n",
    "\n",
    "# Modify an element in the copied object's data (shallow copy behavior)\n",
    "shallow_copy.data[0] = 10\n",
    "print(original.data)  # Output: [10, 2, 3]\n",
    "\n",
    "# Now, assign a new list to the copied object's data\n",
    "shallow_copy.data = [4, 5, 6]\n",
    "print(original.data)  # Output: [10, 2, 3]\n",
    "print(shallow_copy.data)  # Output: [4, 5, 6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next notebooks, we use the following environment wrapper:\n",
    "\n",
    "```python\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, MultiDiscrete, Box\n",
    "import json\n",
    "\n",
    "import ray\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms import ppo\n",
    "\n",
    "from typing import Dict, Literal, Any\n",
    "import copy\n",
    "\n",
    "import grid2op\n",
    "from grid2op.gym_compat import GymEnv, BoxGymObsSpace, DiscreteActSpace, BoxGymActSpace, MultiDiscreteActSpace\n",
    "from lightsim2grid import LightSimBackend\n",
    "\n",
    "\n",
    "class Grid2opEnvWrapper(Env):\n",
    "    def __init__(self,\n",
    "                 env_config: Dict[Literal[\"backend_cls\",\n",
    "                                          \"backend_options\",\n",
    "                                          \"env_name\",\n",
    "                                          \"env_is_test\",\n",
    "                                          \"obs_attr_to_keep\",\n",
    "                                          \"act_type\",\n",
    "                                          \"act_attr_to_keep\"],\n",
    "                                  Any]= None):\n",
    "        super().__init__()\n",
    "        if env_config is None:\n",
    "            env_config = {}\n",
    "\n",
    "        # handle the backend\n",
    "        backend_cls = LightSimBackend\n",
    "        if \"backend_cls\" in env_config:\n",
    "            backend_cls = env_config[\"backend_cls\"]\n",
    "        backend_options = {}\n",
    "        if \"backend_options\" in env_config:\n",
    "            backend_options = env_config[\"backend_options\"]\n",
    "        backend = backend_cls(**backend_options)\n",
    "\n",
    "        # create the grid2op environment\n",
    "        env_name = \"l2rpn_case14_sandbox\"\n",
    "        if \"env_name\" in env_config:\n",
    "            env_name = env_config[\"env_name\"]\n",
    "        if \"env_is_test\" in env_config:\n",
    "            is_test = bool(env_config[\"env_is_test\"])\n",
    "        else:\n",
    "            is_test = False\n",
    "        self._g2op_env = grid2op.make(env_name, backend=backend, test=is_test)\n",
    "        # NB by default this might be really slow (when the environment is reset)\n",
    "        # see https://grid2op.readthedocs.io/en/latest/data_pipeline.html for maybe 10x speed ups !\n",
    "        # TODO customize reward or action_class for example !\n",
    "\n",
    "        # create the gym env (from grid2op)\n",
    "        self._gym_env = GymEnv(self._g2op_env)\n",
    "\n",
    "        # customize observation space\n",
    "        obs_attr_to_keep = [\"rho\", \"p_or\", \"gen_p\", \"load_p\"]\n",
    "        if \"obs_attr_to_keep\" in env_config:\n",
    "            obs_attr_to_keep = copy.deepcopy(env_config[\"obs_attr_to_keep\"])\n",
    "        self._gym_env.observation_space.close()\n",
    "        self._gym_env.observation_space = BoxGymObsSpace(self._g2op_env.observation_space,\n",
    "                                                         attr_to_keep=obs_attr_to_keep\n",
    "                                                         )\n",
    "        # export observation space for the Grid2opEnv\n",
    "        self.observation_space = Box(shape=self._gym_env.observation_space.shape,\n",
    "                                     low=self._gym_env.observation_space.low,\n",
    "                                     high=self._gym_env.observation_space.high)\n",
    "\n",
    "        # customize the action space\n",
    "        act_type = \"discrete\"\n",
    "        if \"act_type\" in env_config:\n",
    "            act_type = env_config[\"act_type\"]\n",
    "\n",
    "        self._gym_env.action_space.close()\n",
    "        if act_type == \"discrete\":\n",
    "            # user wants a discrete action space\n",
    "            act_attr_to_keep =  [\"set_line_status_simple\", \"set_bus\"]\n",
    "            if \"act_attr_to_keep\" in env_config:\n",
    "                act_attr_to_keep = copy.deepcopy(env_config[\"act_attr_to_keep\"])\n",
    "            self._gym_env.action_space = DiscreteActSpace(self._g2op_env.action_space,\n",
    "                                                          attr_to_keep=act_attr_to_keep)\n",
    "            self.action_space = Discrete(self._gym_env.action_space.n)\n",
    "        elif act_type == \"box\":\n",
    "            # user wants continuous action space\n",
    "            act_attr_to_keep =  [\"redispatch\", \"set_storage\", \"curtail\"]\n",
    "            if \"act_attr_to_keep\" in env_config:\n",
    "                act_attr_to_keep = copy.deepcopy(env_config[\"act_attr_to_keep\"])\n",
    "            self._gym_env.action_space = BoxGymActSpace(self._g2op_env.action_space,\n",
    "                                                        attr_to_keep=act_attr_to_keep)\n",
    "            self.action_space = Box(shape=self._gym_env.action_space.shape,\n",
    "                                    low=self._gym_env.action_space.low,\n",
    "                                    high=self._gym_env.action_space.high)\n",
    "        elif act_type == \"multi_discrete\":\n",
    "            # user wants a multi-discrete action space\n",
    "            act_attr_to_keep = [\"one_line_set\", \"one_sub_set\"]\n",
    "            if \"act_attr_to_keep\" in env_config:\n",
    "                act_attr_to_keep = copy.deepcopy(env_config[\"act_attr_to_keep\"])\n",
    "            self._gym_env.action_space = MultiDiscreteActSpace(self._g2op_env.action_space,\n",
    "                                                               attr_to_keep=act_attr_to_keep)\n",
    "            self.action_space = MultiDiscrete(self._gym_env.action_space.nvec)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"action type '{act_type}' is not currently supported.\")\n",
    "            \n",
    "    def reset(self, seed=None, options=None):\n",
    "        # use default _gym_env (from grid2op.gym_compat module)\n",
    "        # NB: here you can also specify \"default options\" when you reset, for example:\n",
    "        # - limiting the duration of the episode \"max step\"\n",
    "        # - starting at different steps  \"init ts\"\n",
    "        # - study difficult scenario   \"time serie id\"\n",
    "        # - specify an initial state of your grid \"init state\"\n",
    "        return self._gym_env.reset(seed=seed, options=options)\n",
    "        \n",
    "    def step(self, action):\n",
    "        # use default _gym_env (from grid2op.gym_compat module)\n",
    "        return self._gym_env.step(action)\n",
    "        \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the grid2op agent\n",
    "\n",
    "In this subsection we briefly explain how to wrap the trained agent (see below for training methods depending on the framework you want to use). The goal is to make this \"tutorial\" complete, in the sense that you will be able to use the trained agent in regular grid2op framework, for example using the `Runner`\n",
    "\n",
    "This subsection is compatible with all code that is explained in this notebook, even though we demonstrate it with the env created above.\n",
    "\n",
    "The basic idea is really simple, you create an grid2op agent, initialize it with the gym_env (you got from the `gym_compat` module) and use the \"gym_env.action_space.from_gym\" and \"gym_env.observation_space.to_gym\" function to convert the action and the observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Agent import BaseAgent\n",
    "\n",
    "class AgentFromGym(BaseAgent):\n",
    "    def __init__(self, gym_env, trained_agent):\n",
    "        self.gym_env = gym_env\n",
    "        BaseAgent.__init__(self, gym_env.init_env.action_space)\n",
    "        self.trained_aget = trained_agent\n",
    "    def act(self, obs, reward, done):\n",
    "        gym_obs = self.gym_env.observation_space.to_gym(obs)\n",
    "        gym_act = self.trained_agent.act(gym_obs, reward, done)\n",
    "        grid2op_act = self.gym_env.action_space.from_gym(gym_act)\n",
    "        return grid2op_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is it. You are done ;-)\n",
    "\n",
    "We recommend you to read the notebook [04_TrainingAnAgent](./04_TrainingAnAgent.ipynb) for more information about this \"template\" agent. And most importantly, some examples of such agents (and \"better\" grid2op environment) are provided in the \"l2rpn_baselines\" package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) RLLIB\n",
    "\n",
    "To make it easier to get started, we moved this into the notebook [11_ray_integration](./11_ray_integration.ipynb)\n",
    "\n",
    "Please have a look at this notebook for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Stable baselines\n",
    "\n",
    "To make it easier to get started, we moved this into the notebook [11_stable_baselines3_integration](./11_stable_baselines3_integration.ipynb)\n",
    "\n",
    "Please have a look at this notebook for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Tf Agents\n",
    "Lastly, the RL frameworks we will use is tf agents.\n",
    "\n",
    "Compared to the previous one, this framework is more verbose. In this notebook we will mimic what has been done in the https://github.com/tensorflow/agents/blob/master/docs/tutorials/1_dqn_tutorial.ipynb\n",
    "\n",
    "To that end, we will introduce the last \"gym transformer\" available in grid2op at time of writing. This function will transform the action space in a Discrete one. With this modeling, the agent can take an action on a substation, or act on a powerline or perform redispatching. But, as opposed to what is done previously, it cannot act on, say, a substation and a powerline at the same time.\n",
    "\n",
    "This limitation does not come from tf agents. But this limitation is necessary to run the tutorial of the DQN provided with tf agents.\n",
    "\n",
    "\n",
    "First we will build the observation space as for the stable baselines repository. See section [2) Stable baselines](#2\\)-Stable-baselines) for more information.\n",
    "\n",
    "### Observation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the gym environment\n",
    "env_tfa = GymEnv(env_glop)  # tfa for \"tf agents\"\n",
    "glop_obs = env_glop.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BoxGymObsSpace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# customize the observation space\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m env_tfa\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;241m=\u001b[39m \u001b[43mBoxGymObsSpace\u001b[49m(env_tfa\u001b[38;5;241m.\u001b[39minit_env\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[0;32m      3\u001b[0m                                           attr_to_keep\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgen_p\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_p\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopo_vect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrho\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_dispatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnectivity_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      5\u001b[0m                                           divide\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgen_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: env_glop\u001b[38;5;241m.\u001b[39mgen_pmax,\n\u001b[0;32m      6\u001b[0m                                                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: glop_obs\u001b[38;5;241m.\u001b[39mload_p,\n\u001b[0;32m      7\u001b[0m                                                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_dispatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: env_glop\u001b[38;5;241m.\u001b[39mgen_pmax},\n\u001b[0;32m      8\u001b[0m                                           functs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnectivity_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\n\u001b[0;32m      9\u001b[0m                                                       \u001b[38;5;28;01mlambda\u001b[39;00m grid2obs: grid2obs\u001b[38;5;241m.\u001b[39mconnectivity_matrix()\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m     10\u001b[0m                                                       \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m                                                       )\n\u001b[0;32m     12\u001b[0m                                                  }\n\u001b[0;32m     13\u001b[0m                                          )\n\u001b[0;32m     14\u001b[0m obs_gym, info \u001b[38;5;241m=\u001b[39m env_tfa\u001b[38;5;241m.\u001b[39mreset()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BoxGymObsSpace' is not defined"
     ]
    }
   ],
   "source": [
    "# customize the observation space\n",
    "env_tfa.observation_space = BoxGymObsSpace(env_tfa.init_env.observation_space,\n",
    "                                          attr_to_keep=[\"gen_p\", \"load_p\", \"topo_vect\",\n",
    "                                                        \"rho\", \"actual_dispatch\", \"connectivity_matrix\"],\n",
    "                                          divide={\"gen_p\": env_glop.gen_pmax,\n",
    "                                                  \"load_p\": glop_obs.load_p,\n",
    "                                                  \"actual_dispatch\": env_glop.gen_pmax},\n",
    "                                          functs={\"connectivity_matrix\": (\n",
    "                                                      lambda grid2obs: grid2obs.connectivity_matrix().flatten(),\n",
    "                                                      0., 1., None, None,\n",
    "                                                      )\n",
    "                                                 }\n",
    "                                         )\n",
    "obs_gym, info = env_tfa.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the observation space might need to be customize. We don't assume here that everything here is relevant, nor that any information that would be needed for an agent is here. \n",
    "\n",
    "This example is only here to demonstrate how to use grid2op with openai gym framework.\n",
    "\n",
    "### Action space\n",
    "\n",
    "As opposed to the previous action space, to use the tutorial of tf agents, we need to customize the action space to ouput a single number (the id of the action you want to take).\n",
    "\n",
    "This can be done with the `DiscreteActSpace` gym converter, that behave approximately the same way as `MultiDiscreteActSpace` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.gym_compat import DiscreteActSpace\n",
    "reencoded_act_space = DiscreteActSpace(env_sb.init_env.action_space,\n",
    "                                       attr_to_keep=[\"set_line_status\", \"set_bus\", \"redispatch\"])\n",
    "env_tfa.action_space = reencoded_act_space\n",
    "obs_gym = env_sb.reset()\n",
    "print(env_tfa.action_space.from_gym(env_tfa.action_space.sample()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env_tfa.action_space.from_gym(env_tfa.action_space.sample()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping up and start training\n",
    "\n",
    "And that is it. All the rest is done thanks to tf agents. \n",
    "\n",
    "tf agents is a lot more verbose than ray and stable baselines, but it allows for more control on what you want to do, we will, for the sake of the example, only show the step without detailing them.\n",
    "\n",
    "For more information, you can visit their github:\n",
    "https://github.com/tensorflow/agents\n",
    "\n",
    "website:\n",
    "https://www.tensorflow.org/agents/api_docs/python/tf_agents\n",
    "\n",
    "and the notebook that inspired this one:\n",
    "https://colab.research.google.com/github/tensorflow/agents/blob/master/docs/tutorials/1_dqn_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the above code, once again, only aims at showing how to integrate grid2op with tf agents. Its aim is not to showcase the best use of tensorflow, tf agents or grid2op.\n",
    "\n",
    "It is only an example for demonstration purpose and do not aim at providing an interesting agent at all. For that you might want to use something different than DQN, tune the hyper parameters (including size of each neural networks, number of step for which you train, learning rate, etc. etc.), define in a better fasshion the action space and observation space etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_agents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdqn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dqn_agent\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_agents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_py_environment\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# initialize the environment\n",
    "from tf_agents.environments.gym_wrapper import GymWrapper\n",
    "tf_env_train = tf_py_environment.TFPyEnvironment(GymWrapper(env_tfa))\n",
    "eval_env = tf_py_environment.TFPyEnvironment(GymWrapper(copy.deepcopy(env_tfa)))\n",
    "\n",
    "# meta parameters\n",
    "num_iterations = nb_step_train\n",
    "\n",
    "initial_collect_steps = 100\n",
    "collect_steps_per_iteration = 1\n",
    "replay_buffer_max_length = 100000\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "log_interval = 200\n",
    "num_eval_episodes = 10 \n",
    "eval_interval = 1000\n",
    "\n",
    "# neural nets (for the agents)\n",
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(tf_env_train.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "    return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# it's output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])\n",
    "\n",
    "# optimizer (for training)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# just a variable to count the number of \"env.step\" performed\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "# create the agent\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    tf_env_train.time_step_spec(),\n",
    "    tf_env_train.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "agent.initialize()\n",
    "\n",
    "# for exploration\n",
    "random_policy = random_tf_policy.RandomTFPolicy(tf_env_train.time_step_spec(),\n",
    "                                                tf_env_train.action_spec())\n",
    "\n",
    "# replay buffer (to store the past actions / states / rewards)\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=tf_env_train.batch_size,\n",
    "    max_length=replay_buffer_max_length)\n",
    "def collect_step(environment, policy, buffer):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "    # Add trajectory to the replay buffer\n",
    "    buffer.add_batch(traj)\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "    for _ in range(steps):\n",
    "        collect_step(env, policy, buffer)\n",
    "collect_data(tf_env_train, random_policy, replay_buffer, initial_collect_steps)\n",
    "\n",
    "# generate the datasets\n",
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "iterator = iter(dataset)\n",
    "\n",
    "# train it\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = environment.step(action_step.action)\n",
    "        episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics\n",
    "\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "    collect_data(tf_env_train, agent.collect_policy, replay_buffer, collect_steps_per_iteration)\n",
    "\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(iterator)\n",
    "    trainer = agent.train(experience)\n",
    "    train_loss = trainer.loss\n",
    "    \n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    \n",
    "if num_iterations:\n",
    "    print('Final Average return aftre training for {} steps: {}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use another RL framework, let us know by filling a github issue template here: https://github.com/Grid2Op/grid2op/issues/new?assignees=&labels=enhancement&template=feature_request.md&title=\n",
    "\n",
    "Even better, if you have used another RL framework, let us know and we will find a way to integrate your developement into this notebook ! You can write an issue https://github.com/Grid2Op/grid2op/issues/new?assignees=&labels=documentation&template=documentation.md&title= and explaining which framework you used and a minimal code example we could use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_g2op",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
